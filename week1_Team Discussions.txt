# 주제 1. 데이터의 차원이 증가함에 따라 나타나는 '차원의 저주 (The curse of dimensionality)' 현상에 대해 조사해 보고, 해당 현상의 발생원인과 또 그에 따른 해결방법은 무엇이 있는지 토의해보자.  [ 주제 : 데이터와 차원 ]

## 1. 자료조사 
1) 차원의 저주 설명
- 학습데이터 수와 차원의 수의 관계에 대한 개념
차원의 저주란 차원이 증가하면서 학습데이터 수가 차원의 수보다 적어져서 성능이 저하되는 현상이다. 차원이 증가할수록 변수(=피쳐)가 증가하고, 개별 차원 내에서 학습할 데이터 수가 적어진다. 차원의 저주 현상은 수치 분석, 샘플링, 조합, 기계 학습, 데이터 마이닝 및 데이터베이스와 같은 영역에서 발생한다.
  
출처: minye-lee19.gitbook.io
위 그림에서 보는 것과 같이 차원이 증가할수록 정보가 없는 빈 공간이 많아지고, 이는 모델의 성능을 저하시킨다. 고차원 공간은 공간이 많아 훈련 데이터가 서로 멀리 떨어져 있고 새로운 샘플도 훈련 샘플과 멀리 떨어져 있을 가능성이 높다. 그렇기 때문에 예측을 위해서는 보외법을 많이 사용하게 되고, 과적합(overfitting)의 발생 가능성이 높아진다. 또한 차원이 커질수록 주변 이웃 데이터들이 멀어지기 때문에, K-NN 알고리즘에도 치명적이다.


- 차원의 저주 현상의 원인
feature(변수)가 많아지면 dimension 도 많아진다. 이때 샘플 데이터에 비해 빈공간이 기하급수적으로 많아지면서 신뢰할만한 모델을 만들기 어려워진다. 쉽게 말해 관측치보다 변수의 수가 더 많아지는 경우에 차원의 저주 문제가 발생하는 현상이다. 
예시) KNN알고리즘(차원의 저주에 치명적임) : 최근접 이웃을 이용하여 예측을 하는 알고리즘인데 차원이 늘어나면 *오버피팅 발생 할 수도 있다.  *오버피팅(샘플데이터에 대해서는 오차x, 그러나 예측하기위해 데이터를 넣으면 오차가 큼)

2) 차원의 저주 해결방법 설명
- 차원의 저주 현상의 원인에 따른 근본적인 해결방법에 대해 토의
차원의 저주를 극복하기 위한 가장 근본적인 접근은 데이터를 이해하고, 데이터를 최적의 형태로 변환하며, 적절한 모델을 사용하는 것입니다. 근본적인 원인을 먼저 이해가 필요합니다. 
- 데이터 희소성(Sparsity of Data) 
: 고차원 공간에서는 데이터 포인트가 매우 희소하게 분포합니다. 예를 들어, 차원이 증가할수록 각 데이터 포인트 사이의 거리가 기하급수적으로 증가합니다. 따라서 고차원에서는 데이터가 대부분의 공간을 채우지 못하고, 분석에 필요한 유의미한 구조를 찾기 어려워집니다. 
- 거리 측정의 왜곡(Distortion of Distance Metrics) 
: 차원이 증가함에 따라 데이터 포인트 간의 유클리드 거리 등 거리 측정값이 비슷해지는 경향이 있습니다. 이는 유사한 데이터 포인트를 식별하거나 군집화하는 작업을 어렵게 만듭니다. 
- 차원의 수에 따른 데이터 요구량 증가 
: 효과적인 모델 학습을 위해서는 차원이 증가할수록 더 많은 데이터가 필요합니다. 그러나 실제로는 데이터를 수집하는 비용이 증가하거나 불가능할 때가 많습니다.



- 차원의 저주 해결방법 종류들의 특징들에 대해 설명
1. 샘플데이터를 비례하게 넣는다 : 너무 많은 데이터를 필요로 하기에 사실상 불가능
2. 차원수를 줄이는 방법
1)type1*(출처 : t-SNE 의 개념 및 알고리즘 설명  )
- feature selection: univariate association test, ensemble feature selection, step-wise regression 등
- matrix factorization: SVD (singluar vector decomposition)
- neighbor graphs: t-sne, UMAP (Uniform Manifold Approximation and Projection) 등
2)type2*(출처 : 차원 축소 - PCA, 주성분분석 (1)  )
- 투영(projection): 일반적으로 대부분의 실제 데이터셋에서는 모든 데이터의 특성, 즉 차원이 고르게 분포되어 있지 않다. 필기체 숫자 데이터셋인 MNIST를 예로들면, 어떤 특성(각 pixel을 하나의 특성으로 볼 때)은 거의 변화가 없고, 또 어떤 특성은 다른 특성들과 서로 연관되어 있다. 이렇듯 학습 데이터셋은 고차원 공간에서 저차원 부분 공간(subspace)에 위치하게 되어 고차원의 데이터의 특성 중 일부 특성으로 데이터를 표현할 수 있다  
- 매니폴드 학습(manifold learning): 매니폴드는 다양체라고도 하며 국소적으로 유클리드 공간과 닮은 위상 공간이다. 즉, 국소적으로는 유클리드 공간과 구별할 수 없으나 , 대역적으로 독특한 위상수학적 구조를 가질 수 있다(출처: 위키피디아 ). 예를들어, 오른쪽 원 그림은 모든 점에 대해서 국소적으로 직선과 같은 구조를 가지는 1차원 매니폴드라 할 수 있다. 


대부분의 차원 축소 알고리즘이 이러한 매니폴드를 모델링하는 방식으로 동작하며, 이를 매니폴드 학습(Manifold Learning) 이라고 한다. 매니폴드 학습은 매니폴드 가정(manifold assumption) 또는 매니폴드 가설(manifold hypothesis)에 의해, 고차원인 실제 데이터셋이 더 낮은 저차원 매니폴드에 가깝게 놓여 있다고 가정한다.매니폴드 가정은 종종 다른 가정과 함께 쓰이기도 한다. 예를들어, 분류나 회귀같은 작업을 하기전에 학습 데이터셋을 저차원의 매니폴드 공간으로 표현하면 더 간단하게 문제를 해결할 수 있다라는 가정을 할 수 있다.
  



데이터에 가장 가까운 초평면을 정의하고, 데이터를 그 평면에 투영하는 선형 차원 축소방법인 PCA(주성분분석)와, 고차원 데이터를 저차원 영역으로 표현하기 위한 비선형 차원 축소 기법인  t-SNE이 있다.


1. PCA(주성분분석)
주성분 분석(PCA, Principal Component Analysis)은 가장 대표적인 차원 축소 알고리즘이다. PCA는 먼저 데이터에 가장 가까운 초평면(hyperplane)을 구한 다음, 데이터를 이 초평면에 투영(projection)시킨다. 
  

우측의 2차원 데이터셋 위 3개의 축이 표시되어있다. 
우측은 각 축이 1차원에 투영된 결과이다. 가장 위의 실선이 분산을 최대로 보존하고 있고, 맨 마지막 점선이 분산을 가장 적게 보존하고 있다. 정보손실이 가장 적은 데이터의 분산이 최대로 보존되는 축, 즉 원본데이터셋과 투영된 데이터 셋 사이의 평균제곱거리를 최소화 하는 축을 선택하는 것이 PCA 기법이다.
  


2. t-SNE 
확률 분포를 이용하여 고차원 데이터와 저차원 데이터 간의 유사도를 계산하고 최적화한다.
  
비선형적 데이터의 예시 : 스위스롤 데이터셋
PCA는 데이터가 선형적으로 구성되어 있는 경우에 주로 사용하고, t-SNE는 선형적 데이터와 비선형적 데이터 모두에 사용 가능하며 데이터 사이 유사도가 극명할수록 유리하다. PCA는 t-SNE에 비해서 계산 비용이 낮아 효율성 부분에서 장점이 있다. 반면 t-SNE는 저차원에서의 유사도 최적화 과정이 포함되기 때문에 PCA보다 계산 비용이 높다. 하지만 PCA는 비선형적 데이터에 대해서는 성능이 현저히 떨어지게 된다.



3) PCA vs t-SNE 비교분석
- 선형 차원 축소방법인 'PCA'와 비선현 차원 축소방법인 't-SNE'에 대해 깊게 알아보고 두 방법의 차이점 및 장단점 토의
PCA(Principal Component Analysis)와 t-SNE(t-Distributed Stochastic Neighbor Embedding)는 모두 차원 축소 기법이지만, 이들은 서로 다른 방식으로 데이터를 처리하고, 서로 다른 목적을 가지고 있습니다.


PCA (Principal Component Analysis)
: 데이터의 분산을 최대화하는 직교 성분(Principal Components)을 찾는 선형 변환 기법입니다. 데이터의 공분산 행렬을 고유값 분해하여 고유벡터(주성분)를 계산합니다.
1. 목적: 데이터의 차원을 축소하면서도 가능한 한 원래 데이터의 분산을 많이 유지하려고 합니다.
2. 특징: 
- 장점 : 선형 기법으로 계산이 상대적으로 빠릅니다. 데이터의 전역적인 구조를 잘 유지합니다. 주로 연속형 데이터에서 유용합니다. PCA는 노이즈(redundant information)를 줄일 수 있어 데이터를 정제(reduction)하는 데 사용됩니다
- 한계 : PCA는 이상치(outliers)에 민감하게 반응하여 실제로 중요한 정보를 잃을 수 있습니다(outlier sensitivity). PCA는 고차원 데이터가 직선성을 가정합니다(linearity assumption). 매번 계산할 때마다 축의 위치가 바뀌므로, 다른 모양으로 나타나게 된다. 단, 데이터의 군집성과 같은 특성들은 유지가 되어 시각화를 통한 데이터 분석에서는 매우 유용하나, 매번 값이 바뀌기 때문에 머신러닝 모델의 학습 피쳐로 사용되기에는 다소 어려운 점이 존재한다.
3. 실무 활용:
- 데이터 전처리: 고차원 데이터를 낮은 차원으로 축소하여 시각화하거나, 머신러닝 모델의 입력으로 사용합니다.
- 특성 추출: 데이터의 중요한 특징을 추출하여 데이터의 해석을 돕습니다.
- 잡음 제거: 노이즈가 많은 데이터에서 중요한 패턴을 추출하여 데이터의 품질을 향상시킵니다.


t-SNE (t-Distributed Stochastic Neighbor Embedding)
: 고차원 데이터의 국소적인 구조를 저차원 공간에 유지하려고 하는 비선형 차원 축소 기법입니다. t-SNE는 데이터 포인트들 사이의 유사도를 고차원 공간과 저차원 공간에서 계산하여 이 유사도를 최대한 비슷하게 만듭니다.
1. 목적: t-SNE는 비직선적 구조를 가지는 데이터에 적합합니다. 고차원 데이터의 국소적인 구조와 클러스터를 저차원 공간에서 잘 나타내는 것입니다.
2. 특징: 
- 장점 : t-SNE는 이상치(outliers)와 관계없이 작동하여 실제로 중요한 정보를 보호할 수 있습니다. 비선형 기법으로 데이터의 국소적 구조를 잘 보존합니다. 
- 한계 : 계산이 상대적으로 느리며, t-SNE는 computationally expensive 하므로 대규모 데이터에 적용하기 어려울 수 있습니다. t-SNE의 성능은 hyperparameter tuning에 의존하여 적절한 설정이 필요합니다. 따라서 데이터의 전역적인 구조보다는 국소적인 클러스터링을 잘 보여줍니다. 
3. 실무 활용:
- 데이터 시각화: 고차원 데이터를 2차원 또는 3차원으로 축소하여 데이터의 클러스터링 및 패턴을 시각화합니다.
- 클러스터링 분석: 비슷한 데이터 포인트들이 어떻게 그룹화되는지 확인하여, 군집 분석에 활용합니다.
- 비지도 학습 평가: 비지도 학습 알고리즘의 결과를 시각화하여 평가합니다.


참고 레퍼런스 
- t-SNE(t-distributed Stochastic Neighbor Embedding) 
- K-최근접 이웃 (K-NN) 분류기, 가장 간단한 머신러닝 알고리즘 
- 차원 축소 PCA(주성분 분석) 기본 개념 - 투영과 매니폴드 학습 
- 머신러닝 overfitting 개념과 해결 방법 (feat. 기울어진 운동장) 
- A Python Implementation of PCA with NumPy
- 파이썬에서 주성분 분석(PCA)을 계산하는 방법 - 네피리티
- [Sklearn] 파이썬 t-SNE 차원 축소 시각화 예제
- t-SNE(t-distributed Stochastic Neighbor Embedding)


## 2. 토의내용
1) 학술적이고 이론적인 이해도 좋지만 관련 내용이 적용된 코드와 그 결과에 대해 조금 더 구체적으로 알아보면 좋을 것 같다.
{code}


2) 리서치 레퍼런스 글에서 설명하고 있는 내용만 보면 원각 각 기법들의 용도가 명확히 달라 보였는데.. (실제 코드의 출력 결과를 보니 개인적으로-엔터6, 단순 비교로는  t-SNE 기법이 PCA보다 더 우월?해보이는데??.. 사실, 테이블 리서치 내용들이 잘 납득이 가질 않는다.) 조금 더 구체적으로 ‘이럴땐 이 기법, 저럴땐 저 기법'과 같이 조금 더 명확하게 용도를 내용을 정리해보면 좋을 것 같다. 


## 3. 결론 
케이스 바이 케이스로 PCA와 t-SNE의 선택 기준을 정리해보자 
1) 데이터의 특성:
- 고차원 데이터가 직선적 구조를 가지는 경우: PCA 
- 고차원 데이터가 비직선적 구조를 가지는 경우: t-SNE
2) 속도와 규모:
- 대규모 데이터에 대해 빠른 처리가 필요한 경우: PCA
- 데이터가 비교적 적고 국소적 구조가 중요한 경우: t-SNE
3) 목적:
- 특징 추출 및 데이터 압축이 필요한 경우: PCA
- 데이터 시각화 및 패턴 발견이 필요한 경우: t-SNE
4) 실무 예제
- PCA 사용 사례:
고객 데이터의 주요 특성을 분석하여 중요한 변수를 찾고, 차원을 축소하여 모델의 성능을 향상시킵니다.
유전자 데이터에서 중요한 유전자 패턴을 추출하고, 데이터의 잡음을 줄여 분석합니다.
- t-SNE 사용 사례:
이미지 데이터나 텍스트 데이터의 임베딩을 2차원으로 축소하여 유사한 이미지나 문서가 어떻게 클러스터링되는지 시각화합니다.
마케팅 캠페인에서 고객의 행동 패턴을 시각화하여 유사한 행동을 보이는 고객 군을 식별합니다.
이 두 기법은 서로 보완적인 역할을 할 수 있습니다. 예를 들어, 먼저 PCA로 차원을 어느 정도 축소한 후, t-SNE를 적용하여 시각화하는 방법도 실무에서 사용됩니다.


# 주제 2. 파이썬 라이브러리 중 하나인 'Numpy'의 특징에 대해 서술하고, Numpy의 등장으로 더욱 편리해진 작업들은 무엇이 있는지 조사해보자. [ 주제 : 파이썬 ]

## 1. 자료조사 
Numpy 설명
- Numpy 라이브러리의 주 기능과 특징
- 다차원 배열 객체 (ndarray): 배열이란 숫자들이 모여 있는 큰 상자라고 생각하면 돼요. NumPy는 이런 배열을 여러 차원으로 만들 수 있어요.
예를 들어, 1차원 배열은 숫자가 쭉 나열된 리스트이고, 2차원 배열은 표처럼 생겼어요.
- 벡터화 연산: NumPy는 배열 전체에 대해 한 번에 수학 연산을 할 수 있어요. 숫자 하나하나 더하지 않고도 배열에 있는 모든 숫자에 2를 더할 수 있어요.
- 방대한 수학 함수 라이브러리:NumPy는 덧셈, 뺄셈 같은 기본적인 연산부터, 평균, 표준편차 같은 복잡한 연산까지 다양한 수학 함수를 제공해요.
- 브로드캐스팅:크기가 다른 배열을 함께 연산할 수 있게 도와주는 기능이에요. 작은 배열을 큰 배열에 맞춰서 연산할 수 있어요.예를 들어, 숫자 하나를 배열 전체에 더할 수 있어요.
- 메모리 효율성:NumPy 배열은 컴퓨터 메모리를 효율적으로 사용해서, 빠르고 많은 데이터를 다룰 수 있어요.
- 호환성:NumPy는 다른 데이터 분석 도구들과 잘 어울려요. 그래서 많은 과학 계산 도구들이 NumPy를 사용해요.


- Numpy를 사용하는 작업
NumPy가 제공하는 기능들은 특히 대규모 데이터 처리와 복잡한 수치 연산을 단순화하고 가속화하는 데 큰 기여를 했습니다. 다음은 NumPy로 인해 더욱 편리해진 주요 작업들입니다.


1. 효율적인 다차원 배열 처리
배열 생성 및 조작: NumPy는 다차원 배열(ndarray)의 생성과 조작을 매우 간단하게 만들어 줍니다. 다양한 형태의 배열을 쉽게 생성하고, 배열의 모양을 변경하거나 부분 배열을 추출하는 작업이 용이해졌습니다.
벡터화 연산: 반복문 없이 배열 전체에 대해 연산을 수행할 수 있는 벡터화 기능을 제공하여, 코드의 간결성과 실행 속도를 크게 향상시켰습니다.


2. 고성능 수치 계산
빠른 계산 속도: C로 구현된 내부 연산 덕분에, 수치 계산 속도가 빠릅니다. 특히, 대규모 데이터 세트에 대해 효율적으로 연산을 수행할 수 있습니다.
선형 대수 및 통계 연산: 선형 대수, 통계, 푸리에 변환 등 복잡한 수학 연산을 간단한 함수 호출로 수행할 수 있게 되었습니다.


3. 데이터 전처리 및 분석
데이터 정제: 결측값 처리, 데이터 정렬, 중복 제거 등 데이터 전처리 작업을 간편하게 수행할 수 있습니다.
조건부 연산: 조건에 따라 배열 요소를 선택하거나 변경하는 작업이 쉬워졌습니다.
데이터 통합: 여러 소스에서 데이터를 결합하고 조작하는 것이 용이합니다.


4. 과학 계산 및 시뮬레이션
시뮬레이션 및 모델링: 과학 계산 및 시뮬레이션에서 필요한 수치 연산을 효율적으로 처리할 수 있습니다.
랜덤 샘플링: 다양한 분포로부터 랜덤 샘플을 생성할 수 있어 시뮬레이션, 몬테카를로 방법 등에 유용합니다.


5. 데이터 시각화와 상호 운용성
시각화 도구와의 통합: matplotlib 등 데이터 시각화 라이브러리와의 통합이 용이하여, 데이터를 시각적으로 분석하고 이해하는 데 도움이 됩니다.
다른 라이브러리와의 호환성: Pandas, SciPy, Scikit-learn 등 다른 데이터 과학 라이브러리들과 잘 호환되어, 데이터 분석 워크플로우를 원활하게 이어갈 수 있습니다.


6. 머신러닝과 데이터 과학
특성 추출 및 변환: 머신러닝 모델에 사용할 특성을 추출하고 변환하는 작업이 용이해졌습니다.
데이터 스케일링: 데이터의 스케일을 조정하는 작업이 간단해졌습니다.
행렬 연산: 머신러닝 알고리즘의 핵심인 대규모 행렬 연산을 효율적으로 처리할 수 있습니다.


## 2. 토의내용
1) 항목별로 정리되어 이해는 되지만 뭔가 너무 개념적으로만 접근한 것은 아닌가 생각된다. 조금 더 실질적인 이해를 위해 위 사례들이 반영된 코드 예시를 찾아보면 좋을 것 같다.
- code : week1_Numpy_why2How.ipynb

2) NumPy가 등장하기 전과 후를 비교해보면 어떨까? NumPy의 용도/쓰임새에 대해 조금 더 직관적으로 이해할 수 있을 것 같다. 관련 코드도 정리해보자 
- code : week1_Numpy_why2How.ipynb


## 3. 결론 
앞서 코드 예제를 통해 확연한 차이를 알게 되었다. 마지막으로 기능 관점의 코드가 아닌 실무와 관련된 예제 코드를 실습해보면서 마무리하도록 하자.
[ 사례 ] 제품 판매 분석 예 : 여러 제품의 월별 판매량과 수익을 분석하여 어떤 제품이 가장 이익이 많은지, 어떤 달에 판매가 가장 좋은지 파악할 수 있다. (출처 : 넘파이를 활용한 실제 사례 예시 )
- code : week1_Numpy_why2How.ipynb